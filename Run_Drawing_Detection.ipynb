{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"MNIST_Numeric_predictor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a lower and upper bound for what we want to track\n",
    "#Green color range\n",
    "lower = np.array([33, 80, 40])\n",
    "upper = np.array([100, 255, 255])\n",
    "\n",
    "#Opening is used to remove noise in detected images. \n",
    "#It works by filtering out bounderies of detected images, and then dilating them to fill in the bounderies\n",
    "kernel_open = np.ones((6, 6))\n",
    "\n",
    "#Closing is the opposite. It dilates and then erodes in order to fill in missing detections within detected images.\n",
    "kernel_close = np.ones((10,10))\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#We need to create an empty black screen to write our drawn shapes onto. This is so we can recreate something similar to MNIST drawings.\n",
    "black = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "prediction = -1\n",
    "\n",
    "#Create a list in order to store the detected locations of our green object. \n",
    "#This will be used to stitch together a number that is sent to the CNN\n",
    "draw_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)   \n",
    "while True:\n",
    "    (grabbed, frame) = video.read()\n",
    "\n",
    "    if not grabbed:\n",
    "        video.release()\n",
    "        break\n",
    "    \n",
    "    #flip the frame so that we do not need to draw backwards\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    #Convert from a blue green red colorspace to hue saturation value colorspace.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Apply a masking function using our preset color boundaries. This allows us to retrieve our detected\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    #Apply the closing and opening functions in order to get a clearer detected image.\n",
    "    #Explanation: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html\n",
    "    mask_open = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)\n",
    "    mask_close = cv2.morphologyEx(mask_open,cv2.MORPH_CLOSE,kernel_close)\n",
    "    \n",
    "    mask = mask_close\n",
    "    \n",
    "    #Get a contour of the detected image. Before this step, we could have applied a threshold function. However, it performed well enough without it.\n",
    "    #The RETR_EXTERNAL parameter tells the function to just get the outline of the contour.\n",
    "    #The CHAIN_APPROX_NONE tells the function not to approximate the contour output. We could have used CHAIN_APPROX_SIMPLE, but memory was not an issue.\n",
    "    (not_needed, contours, not_needed) = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    #Draw a blue square around the immediate object\n",
    "    cv2.drawContours(frame, contours, -1, (255, 0, 0), 3)\n",
    "    \n",
    "    #Draw a nonrotating red rectangle that always encompasses the largest value in the xy dimensions\n",
    "    for i in range(len(contours)):\n",
    "        x,y,w,h=cv2.boundingRect(contours[i])\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255), 2)\n",
    "        cv2.putText(frame, str(i+1),(x,y-10),font,0.55,(0,255,0),1)\n",
    "    \n",
    "    #If we have a contour in the image\n",
    "    if len(contours) >= 1:\n",
    "        #How to get center of object using moments: \n",
    "        #https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/\n",
    "        contour = sorted(contours, key = cv2.contourArea)[-1]\n",
    "        moment = cv2.moments(contour)\n",
    "        center = (int(moment['m10'] / moment['m00']), int(moment['m01'] / moment['m00']))\n",
    "        draw_points.append(center)\n",
    "        \n",
    "    #If we don't have contours now, but they used to be present.\n",
    "    #In other words, we hid our object. So we should make a prediction\n",
    "    elif len(contours) == 0 and len(draw_points) > 0:\n",
    "        \n",
    "        #Explanation of gaussian filtered w/ Otsu's thesholding:\n",
    "        #https://docs.opencv.org/3.4.0/d7/d4d/tutorial_py_thresholding.html\n",
    "        \n",
    "        #Grayscale version is used to create a binary contour\n",
    "        gray = cv2.cvtColor(black, cv2.COLOR_BGR2GRAY)\n",
    "        gaussian = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        threshold = cv2.threshold(gaussian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        blackboard_contours = cv2.findContours(threshold.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "       \n",
    "        #If the blackboard has a contour\n",
    "        if len(blackboard_contours) >= 1:\n",
    "            \n",
    "            contour = sorted(blackboard_contours, key = cv2.contourArea)[-1]\n",
    "            \n",
    "            if cv2.contourArea(contour) >= 1500:\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                number = gray[y : y + height + 50, x : x + width + 50]\n",
    "                resized = cv2.resize(number, (28, 28))\n",
    "                array = np.array(resized)\n",
    "                result = array.astype('float32')/255\n",
    "\n",
    "                prediction = model.predict(result.reshape(1,28,28, 1))[0]\n",
    "                prediction = np.argmax(prediction)\n",
    "                \n",
    "        #Reset the drawing for the next prediction\n",
    "        draw_points = []\n",
    "        black = np.zeros((480, 640, 3), dtype = np.uint8)\n",
    "\n",
    "    #Display the drawing on the webcam, as well as on the black screen\n",
    "    for i in range(1, len(draw_points)):\n",
    "        if (draw_points[i - 1] is not None and draw_points[i] is not None):\n",
    "            cv2.line(frame, draw_points[i - 1], draw_points[i], (50, 200, 50), 5)\n",
    "            cv2.line(black, draw_points[i - 1], draw_points[i], (255, 255, 255), 30)\n",
    "    \n",
    "    \n",
    "    cv2.putText(frame, \"CNN: \" + str(int(prediction)), (10, 50), font,1, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"cam\",frame)\n",
    "    \n",
    "    #Press escape key to close the program\n",
    "    k = cv2.waitKey(33)\n",
    "    if k==27:  \n",
    "        prediction = -1\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
